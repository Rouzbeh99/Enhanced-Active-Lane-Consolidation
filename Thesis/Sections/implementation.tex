
\newpage
\chapter{ALC as a Compiler Transformation}
\label{chap:alc-pass}


Like most optimizations in modern compilers, the ALC transformation is designed with two components:
\begin{inparaenum}[(i)]
    \item an analysis that identifies candidates loops to apply ALC based on loop features, such as the number of instructions on each \cpath and the CFG complexity (\rsec{alc-analysis}); and
    \item a transformation that applies active-lane consolidation to candidate loops that have enough instructions in each \cpath and low memory-to-compute instruction ratio to amortize vector-permutation costs  (\rsec{alc-transformation}).
\end{inparaenum}

\section{ALC Analysis}
\label{sec:alc-analysis}

The main goals of the analysis are two-fold:
\begin{inparaenum}
\item to identify candidate loops to apply ALC by checking for the legality of applying ALC; and \item decide if a given candidate would benefit from the ALC transformation.
\end{inparaenum}
It is legal to apply ALC to a loop $L$ with control-flow divergence if $L$ does not have \emph{loop-carried dependencies} and only contains calls to vectorizable functions without side effects (e.g. square-root and sine \& cosine).
Similar to other forms of vectorization such as loop vectorization and SLP vectorization, ALC cannot be applied to loops with loop-carried dependencies because instructions from different iterations that depend on each other, usually, cannot execute in parallel in a SIMD fashion.
The ALC analysis relies on existing data-dependency analysis available on modern compilers to identify loops without loop-carried dependencies.
A data-dependency analysis may return a {\it may depend} answer  because of unresolved alias relationships and, in that case, the compiler must conservatively not apply the transformation~\cite{Landi1991PointerAliasing, Horwitz1997MayAliasNPHard}.

The cost portion of the profitability analysis for ALC uses the estimated cost of executing the new instructions required to perform index and data-vector permutations for ALC minus the instructions that are eliminated by ALC. 
The estimated execution latency of instructions is generally available in a modern compiler because the same information is used in other transformations, such as the creation of an efficient instruction schedule.
The benefit of ALC results from the increased utilization of SIMD units due to the consolidation of loop iterations with the same predicate on the same vector.
Thus the benefit depends on the number of instructions and on the latency of the instructions executed in each of the control-flow paths in the loop.
The distribution of true and false predicates in the iterations of the loop also affects the benefit of ALC.
However, this information can usually only be obtained from profiling, thus it is not used in the profitability analysis for static compilation.

\iffalse
\del{
Once the analysis determines that it is legal to apply ALC to a given loop, then it estimates if said loop would benefit from the transformation.
Such cost/benefit estimation is very challenging as both cost and improvement from the transformation depend on several factors, and might not even be available until the program runs.
Nevertheless, the costs of applying ALC, mainly added by the index and data vector permutations, can be estimated based on the latency of instructions which are used to perform the permutations.
The latency of each instructions, or an estimated latency, is available on most compiler as such information is used by other optimizations, such as finding an efficient instruction schedule.
Thus the ALC costs can be estimated as simply the added cycles needed to execute the instructions that perform index and data-vector permutation.
The benefits of ALC stem from increasing the utilization of SIMD units by avoiding executing the \ifconverted path.
Therefore, better performance is achieved when control-flow dependent loops have paths with a significant number of instructions.
For the purpose of the ALC transformation, significant number of instructions means more instructions than, or instructions that take at least the same amount of cycles as, the permutation code.
}
\fi

Empirically, and as the results in Chapter \ref{chap:evaluation} support, the following factors are key when making the decision of whether or not to apply ALC:
\begin{inparaenum}
    \item Number of instructions on each \cpath;
    \item Number of store operations in the loop (See \rsec{eval-scatters-costs});
    \item Complexity of Loop's CFG (See \rsec{eval-single-if}).
\end{inparaenum}
ALC should be applied to loops that have enough instructions in each \cpath so that the overhead of index and data-vector permutation can be amortized.
As the results in \rsec{gathers-scatters-are-bad} indicate, gather/scatter instructions can significantly hurt ALC's performance.
Although gather instructions can be eliminated through data permutation, it is not possible to avoid all scatter instructions.
Therefore, a loop that has a high ratio of memory-access instructions to compute instructions is not likely to benefit from ALC.
In the current prototype, a conservative approach is used due to the absence of accurate branch probability information: ALC is only applied to loops with two, or fewer, \cpaths.
Future development may seek to integrate branch probability information in the profitability analysis of ALC or may explore a more aggressive application of ALC even in the absence of such information.
If the compiler does not know which path is more likely to be taken, then active-lane consolidation needs to be applied for each \cpath.
Such unbounded application of ALC is not likely to achieve better performance than \ifconverted code because of the permutation costs for all paths. 
Except for the branch probabilities, all other information can be obtained statically by a compiler, avoiding any need for profiling, in contrast to Wyatt \etal's work \cite{praharenka_vectorizing_2022}.

In some loops with more than two \cpaths, it may be legal to apply loop fission to generate multiple loops in such a way that at least some of the resulting loops have two or fewer \cpaths.
The condition to apply loop fission to a loop is that no loop-independent dependency may cross the point where the loop is split.
Profitability analysis for loop fission has to take into account that after fission some loops may exhibit worse cache locality, for instance when different paths use/load the same data.
The study of combining loop fission with ALC is not investigated in this thesis.

\section{ALC Transformation}
\label{sec:alc-transformation}

The actual loop transformation to perform ALC is quite straightforward.
First, scalar instructions that compute the conditions that control each \cpath are replaced with their vector equivalents, forming predicate vectors.
After that, if the loop being transformed has only a single \cpath, then the transformation produces the code that chooses between the \ifconverted path and ALC path, as discussed in \rsec{single-if-statement-approach}.
For loops with two \cpaths, the code produced chooses between one of the two consolidated uniform paths (see \rsec{alc-data-permutation}).
Then, for each \cpath, a consolidated uniform path is generated by traversing each scalar instruction in the path and generating its vector equivalent.
After that, and only if the loop has a single \cpath, the transformation generates the \ifconverted path.
For loops with a number of iterations that is not a multiple of VF, the transformation generates a remainder scalar loop to process the remaining elements.
Loops with fewer than VF elements are left untouched by the ALC transformation.

\section{Implementation in LLVM}

A prototype implementation developed in LLVM is used to  evaluate both ALC analysis \& transformation passes in this work.
LLVM is a \emph{de-facto} standard compiler framework widely used by both industry and academia.
The ALC analysis reuses the memory dependency and alias analysis used by LLVM's loop vectorized pass to determine if loops are loop-carried dependency free.
Both analysis \& transformation are passes in LLVM's intermediate representation (\acrshort{ir}) level.
For now, the transformation pass only generates code for Arm's SVE architecture, and it accomplishes this by using SVE intrinsics available at IR level in LLVM.
However, all architecture-specific intrinsic calls are generated through an interface that, with minimum effort, can be extended to generate code for other architectures that also support SVE.

